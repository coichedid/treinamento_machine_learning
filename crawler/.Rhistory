getwd()
aux <- c(0.0575,0.0128,0.0263,0.0285,0.0913,
0.0173,0.0133,0.0313,0.0599,0.0006,
0.0084,0.0335,0.0235,0.0596,0.0689,
0.0192,0.0008,0.0508,0.0567,0.0706,
0.0334,0.0069,0.0119,0.0073,0.0164,
0.0007,0.1928)
pb  <- matrix(NA,27,2)
colnames(pb) <- c("p[i]","h(p[i])")
rownames(pb) <- c("a","b","c","d","e","f",
"g","h","i","j","k","l",
"m","n","o","p","q","r",
"s","t","u","v","w","x",
"y","z","-")
pb[,1] <- aux
sum(aux)  # nao soma 1, mas e' erro de aproximacao
#===========================================================
# Informacao de Shanon
#===========================================================
pb[,2] <- log2(1/aux)
pb
#===========================================================
# Exemplo
#===========================================================
# A f.d.p. de uma exponencial
#===========================================================
lambda1 <- 2   # valor caracteristico (parametro)
lambda2 <- 5   # valor caracteristico (parametro)
lambda3 <- 10  # valor caracteristico (parametro)
x       <- seq(-1,30,length=1000) # grade de valores
fx1     <- dexp(x,rate=1/lambda1) # f.d.p.
fx2     <- dexp(x,rate=1/lambda2) # f.d.p.
fx3     <- dexp(x,rate=1/lambda3) # f.d.p.
x11()
plot(x,fx1,type="l",lwd=2,col=1,xlab=expression(x),
ylab=expression(f(x))) # densidade p/ lambda=2
lines(x,fx2,col=2,lwd=2)    # densidade p/ lambda=5
lines(x,fx3,col=4,lwd=2)    # densidade p/ lambda=10
legend(20,0.4,              # legenda do grafico
legend=c(expression(paste(lambda,"=1",sep="")),
expression(paste(lambda,"=5",sep="")),
expression(paste(lambda,"=10",sep=""))),
lty=rep(1,3),lwd=rep(2,3),col=c(1,2,4),bty="n")
#===========================================================
# Geracao de numeros aleatorios
#===========================================================
N  <- 1000                    # tamanho da amostra
y1 <- rexp(N,rate=1/lambda1)  # amostra gerada de lambda=2
y2 <- rexp(N,rate=1/lambda2)  # amostra gerada de lambda=5
y3 <- rexp(N,rate=1/lambda3)  # amostra gerada de lambda=10
x11()
par(mfrow=c(1,3))
hist(y1,nclass=20,prob=T,main="",
xlab=expression(x),ylab=expression(f(x)))
lines(x,fx1,col=1,lwd=2)       # densidade p/ lambda=5
hist(y2,nclass=20,prob=T,main="",
xlab=expression(x),ylab=expression(f(x)))
lines(x,fx2,col=2,lwd=2)       # densidade p/ lambda=5
hist(y3,nclass=20,prob=T,main="",
xlab=expression(x),ylab=expression(f(x)))
x   <- seq(-1,600,length=1000) # grade de valores
fx3 <- dexp(x,rate=1/lambda3)  # f.d.p.
lines(x,fx3,col=4,lwd=2)       # densidade p/ lambda=10
#===========================================================
# Exemplo
#===========================================================
# A f.d.p. de uma exponencial
#===========================================================
lambda1 <- 2   # valor caracteristico (parametro)
lambda2 <- 5   # valor caracteristico (parametro)
lambda3 <- 10  # valor caracteristico (parametro)
x       <- seq(-1,30,length=1000) # grade de valores
fx1     <- dexp(x,rate=1/lambda1) # f.d.p.
fx2     <- dexp(x,rate=1/lambda2) # f.d.p.
fx3     <- dexp(x,rate=1/lambda3) # f.d.p.
x11()
plot(x,fx1,type="l",lwd=2,col=1,xlab=expression(x),
ylab=expression(f(x))) # densidade p/ lambda=2
lines(x,fx2,col=2,lwd=2)    # densidade p/ lambda=5
lines(x,fx3,col=4,lwd=2)    # densidade p/ lambda=10
legend(20,0.4,              # legenda do grafico
legend=c(expression(paste(lambda,"=1",sep="")),
expression(paste(lambda,"=5",sep="")),
expression(paste(lambda,"=10",sep=""))),
lty=rep(1,3),lwd=rep(2,3),col=c(1,2,4),bty="n")
lambda   <- seq(0.001,100,length=1000)
flambda1 <- dexp(3,1/lambda)
flambda2 <- dexp(5,1/lambda)
flambda3 <- dexp(12,1/lambda)
x11()
plot(lambda,flambda1,type="l",lwd=2,col=1,xlab=expression(x),
ylab=expression(L(lambda)))   # verossimilhanca x=3
lines(rep(3,2),c(0,max(flambda1)),col=1,lwd=2,lty=2)
lines(lambda,flambda2,col=2,lwd=2) # verossimilhanca x=5
lines(rep(5,2),c(0,max(flambda2)),col=2,lwd=2,lty=2)
lines(lambda,flambda3,col=4,lwd=2) # verossimilhanca x=12
lines(rep(12,2),c(0,max(flambda3)),col=4,lwd=2,lty=2)
legend(40,0.1,              # legenda do grafico
legend=c(expression(paste(x,"=3",sep="")),
expression(paste(x,"=5",sep="")),
expression(paste(x,"=12",sep=""))),
lty=rep(1,3),lwd=rep(2,3),col=c(1,2,4),bty="n")
lambda1 <- 2   # valor caracteristico (parametro)
lambda2 <- 5   # valor caracteristico (parametro)
lambda3 <- 10  # valor caracteristico (parametro)
xtrc    <- seq(0,22,length=1000) # grade de valores
fx1trc  <- dexptrunc(xtrc,rate=1/lambda1,1,20) # f.d.p.
fx2trc  <- dexptrunc(xtrc,rate=1/lambda2,1,20) # f.d.p.
fx3trc  <- dexptrunc(xtrc,rate=1/lambda3,1,20) # f.d.p.
x11()
plot(xtrc,fx1trc,type="l",lwd=2,col=1,xlab=expression(x),
ylab=expression(f(x))) # densidade p/ lambda=2
lines(xtrc,fx2trc,col=2,lwd=2) # densidade p/ lambda=5
lines(xtrc,fx3trc,col=4,lwd=2) # densidade p/ lambda=10
legend(10,0.4,              # legenda do grafico
legend=c(expression(paste(lambda,"=1",sep="")),
expression(paste(lambda,"=5",sep="")),
expression(paste(lambda,"=10",sep=""))),
lty=rep(1,3),lwd=rep(2,3),col=c(1,2,4),bty="n")
lambda1 <- 2   # valor caracteristico (parametro)
lambda2 <- 5   # valor caracteristico (parametro)
lambda3 <- 10  # valor caracteristico (parametro)
x       <- seq(-1,30,length=1000) # grade de valores
fx1     <- dexp(x,rate=1/lambda1) # f.d.p.
fx2     <- dexp(x,rate=1/lambda2) # f.d.p.
fx3     <- dexp(x,rate=1/lambda3) # f.d.p.
x11()
plot(x,fx1,type="l",lwd=2,col=1,xlab=expression(x),
ylab=expression(f(x))) # densidade p/ lambda=2
lines(x,fx2,col=2,lwd=2)    # densidade p/ lambda=5
lines(x,fx3,col=4,lwd=2)    # densidade p/ lambda=10
legend(20,0.4,              # legenda do grafico
legend=c(expression(paste(lambda,"=1",sep="")),
expression(paste(lambda,"=5",sep="")),
expression(paste(lambda,"=10",sep=""))),
lty=rep(1,3),lwd=rep(2,3),col=c(1,2,4),bty="n")
dexptrunc <- function(x,rate=1,a=0,b=Inf){
n   <- length(x)
onx <- as.numeric(x<a | x>b)
aux <- pexp(b,rate)-pexp(a,rate)
out <- onx*rep(0,n)+(1-onx)*dexp(x,rate)/aux
return(out)
}
lambda1 <- 2   # valor caracteristico (parametro)
lambda2 <- 5   # valor caracteristico (parametro)
lambda3 <- 10  # valor caracteristico (parametro)
xtrc    <- seq(0,22,length=1000) # grade de valores
fx1trc  <- dexptrunc(xtrc,rate=1/lambda1,1,20) # f.d.p.
fx2trc  <- dexptrunc(xtrc,rate=1/lambda2,1,20) # f.d.p.
fx3trc  <- dexptrunc(xtrc,rate=1/lambda3,1,20) # f.d.p.
x11()
plot(xtrc,fx1trc,type="l",lwd=2,col=1,xlab=expression(x),
ylab=expression(f(x))) # densidade p/ lambda=2
lines(xtrc,fx2trc,col=2,lwd=2) # densidade p/ lambda=5
lines(xtrc,fx3trc,col=4,lwd=2) # densidade p/ lambda=10
legend(10,0.4,              # legenda do grafico
legend=c(expression(paste(lambda,"=1",sep="")),
expression(paste(lambda,"=5",sep="")),
expression(paste(lambda,"=10",sep=""))),
lty=rep(1,3),lwd=rep(2,3),col=c(1,2,4),bty="n")
lambdatrc   <- seq(0.001,50,length=1000)
flambda1trc <- dexptrunc(3,1/lambdatrc,1,20)
flambda2trc <- dexptrunc(5,1/lambdatrc,1,20)
flambda3trc <- dexptrunc(12,1/lambdatrc,1,20)
x11()
plot(lambdatrc,flambda1trc,type="l",lwd=2,col=1,
xlab=expression(x),ylab=expression(L(lambda))) # veros x=3
lines(rep(3,2),c(0,max(flambda1trc)),col=1,lwd=2,lty=2)
lines(lambdatrc,flambda2trc,col=2,lwd=2) # verossimilhanca x=5
lines(rep(5,2),c(0,max(flambda2trc)),col=2,lwd=2,lty=2)
lines(lambdatrc,flambda3trc,col=4,lwd=2) # verossimilhanca x=12
lines(rep(12,2),c(0,max(flambda3trc)),col=4,lwd=2,lty=2)
legend(40,0.1,              # legenda do grafico
legend=c(expression(paste(x,"=3",sep="")),
expression(paste(x,"=5",sep="")),
expression(paste(x,"=12",sep=""))),
lty=rep(1,3),lwd=rep(2,3),col=c(1,2,4),bty="n")
n           <- 6
xsample     <- c(1.5,2,3,4,5,12)
ngrid       <- 1000
lambdatrc   <- seq(0.001,100,length=ngrid)
flambdatrc  <- rep(NA,ngrid)
for(i in 1:ngrid){
aux <- dexptrunc(xsample[1],1/lambdatrc[i],1,20)
for(j in 2:n)
aux <- aux*dexptrunc(xsample[j],1/lambdatrc[i],1,20)
flambdatrc[i] <- aux
}
x11()
plot(lambdatrc,flambda1trc,type="l",lwd=2,col=1,
xlab=expression(x),ylab=expression(L(lambda)))
setwd("~/treinamento_machine_learning")
dir.create("crawler")
setwd("./crawler/")
?require
library(xml)
install.packages("xml")
source('~/treinamento_machine_learning/crawler/crawler.R')
install.packages("XML")
source('~/treinamento_machine_learning/crawler/crawler.R')
root
nameS(root)
names(root)
?readHTMLTable
# rm(list=ls())
#====================================================
# Exemplo 1 para gerar de uma mistura discreta de
# duas normais
#====================================================
set.seed(12345)
n      <- 100000 # Tamanho da amostra
omega  <- 0.3
mu1    <- 10
sigma1 <- 1
mu2    <- 15
sigma2 <- 1.5
y      <- rbinom(n,1,omega)
mu     <- y*mu1    + (1-y)*mu2
sigma  <- y*sigma1 + (1-y)*sigma2
x      <- rnorm(n,mu,sigma)
x11()
hist(x,nclass=50,prob=T,main="",cex.axis=2,cex.lab=2,col="darkgreen")
xseq <- seq(5,22,length=1000)
yseq <- omega*dnorm(xseq,mu1,sigma1)+(1-omega)*dnorm(xseq,mu2,sigma2)
lines(xseq,yseq,col=2,lwd=3)
#====================================================
# Exemplo 2 para gerar de uma mistura discreta de
# duas normais pelo metodo da amostragem ponderada
#====================================================
# Proposta U(0,20)
m      <- 50000  # reamostragem
xprop  <- runif(n,0,20)
pesos  <- 20*(     omega*dnorm(xprop,mu1,sigma1)
+(1-omega)*dnorm(xprop,mu2,sigma2))
prob   <- pesos/sum(pesos)
sum(prob)
y      <- sample(xprop,m,replace=T,prob=prob)
x11()
hist(y,nclass=50,prob=T,main="",cex.axis=2,cex.lab=2,col="darkgreen")
xseq <- seq(5,22,length=1000)
yseq <- omega*dnorm(xseq,mu1,sigma1)+(1-omega)*dnorm(xseq,mu2,sigma2)
lines(xseq,yseq,col=2,lwd=3)
mu     <-  omega*mu1+(1-omega)*mu2
mu
# valor esperado da variancia condicional
aux1   <- omega*(sigma1^2)+(1-omega)*(sigma2^2)
# variancia do valor esperado condicional
aux2   <- omega*(mu1-mu)^2+(1-omega)*(mu2-mu)^2
sig2   <- aux1+aux2
sig2 # Vamos escolher um valor um pouco maior: 9
m      <- 50000  # reamostragem
xprop  <- rnorm(n,mu,3)
pesos  <- ( (     omega*dnorm(xprop,mu1,sigma1)
+(1-omega)*dnorm(xprop,mu2,sigma2))/
dnorm(xprop,mu,3) )
prob   <- pesos/sum(pesos)
sum(prob)
z      <- sample(xprop,m,replace=T,prob=prob)
x11()
hist(z,nclass=50,prob=T,main="",cex.axis=2,cex.lab=2,col="darkgreen")
xseq <- seq(5,22,length=1000)
yseq <- omega*dnorm(xseq,mu1,sigma1)+(1-omega)*dnorm(xseq,mu2,sigma2)
lines(xseq,yseq,col=2,lwd=3)
any(z>20)
# rm(list=ls())
#====================================================
# Exemplo: analise bayesiana de dados Binomial(m,pix)
# com priori beta(a,n)
# Ver exemplo_08.r
#====================================================
set.seed(12345)
#====================================================
# Primeiro, vamos gerar dados artificiais da Binomial
# Uma amostra aleatoria simples de Bin(m;pix)
#====================================================
m     <- 10   # Numero de ensaios de Bernoulli
pix   <- 0.8  # Probabilidade de sucesso
#====================================================
# Agora, vamos calcular todas as probabilidades
# Serve para efeito de comparacoes
#====================================================
xseq  <- 0:m
probx <- dbinom(xseq,m,pix)
x11()
plot(xseq,probx,type="h",lwd=3,col=4,
xlab=expression(x),ylab=expression(f(x)))
#====================================================
# Gerando uma amostra aleatoria de Bin(m;pix)
#====================================================
n    <- 15     # Tamanho da amostra
x    <- rbinom(n,m,pix)
#====================================================
# Funcao de verossimilhanca de pix
# pix deve ser escalar e x vetor
#====================================================
verox <- function(pix,x){
out <- prod(dbinom(x,m,pix))
return(out)
}
K     <- 999 # tamanho da sequencia
xpix  <- seq(0.001,0.999,length=K)
ypix  <- rep(NA,K)
for(i in 1:K) ypix[i] <- verox(xpix[i],x)
c     <- sum(ypix*0.001) # constante
x11()
plot(xpix,ypix/c,type="l",lwd=3,col=4,
xlab=expression(pi),ylab=expression(L(pi)))
points(rep(mean(x)/m,2),c(0,max(ypix)/c),type="h",
col=2,lwd=2,lty=2)
legend(0,10,legend=c("Verossimilhança","EMV"),bty="o",
col=c(4,2),lwd=rep(2,2),lty=c(1,2))
#====================================================
# A estimativa de maxima verossimilhanca
#====================================================
pixmv <- mean(x)/m
pixmv
#====================================================
# Distribuicao a prior: Triangular( a , b, c)
# com a < b < c,  a=0  e c=1.
#
# f(pix) = 2*pix/b*I[0,b) + 2*(1-pix)/(1-b)*I[b,1]
#
#====================================================
b     <- 0.7
zpix  <- c(2*(xpix[xpix<b]/b),2*(1-xpix[xpix>=b])/(1-b))
x11()
plot(xpix,ypix/c,type="l",lwd=3,col=4,
xlab=expression(pi),ylab=expression(L(pi)))
points(rep(mean(x)/m,2),c(0,max(ypix)/c),type="h",
col=2,lwd=2,lty=2)
lines(xpix,zpix,col=3,lwd=2)
legend(0,10,legend=c("Verossimilhança","EMV","Priori"),
bty="o",col=c(4,2,3),lwd=rep(2,3),lty=c(1,2,1))
#====================================================
# Dist. a posteriori: verossimilhanca binomial
# priri triangular
#====================================================
wpix  <- ypix*zpix
d     <- sum(wpix*0.001) # constante
x11()
plot(xpix,ypix/c,type="l",lwd=3,col=4,
xlab=expression(pi),ylab=expression(L(pi)))
points(rep(mean(x)/m,2),c(0,max(ypix)/c),type="h",
col=2,lwd=2,lty=1)
lines(xpix,zpix,col=3,lwd=2)
lines(xpix,wpix/d,col=5,lwd=2)
legend(0,10,legend=c("Verossimilhança","EMV","Priori",
"Posteriori"),bty="o",col=c(4,2,3,5),
lwd=rep(2,4),lty=c(1,2,1,1))
install.packages("triangle")
#
#====================================================
xbar   <- mean(x)
apost  <- n*xbar + 1     # parametro da proposta
bpost  <- n*(m-xbar) + 1 # parametro da proposta
N      <- 50000          # Tamanho da amostra
M      <- 10000          # Reamostragem
#====================================================
# Gerando da proposta
#====================================================
piprop <- rbeta(N,apost,bpost)
#====================================================
# Note que calcularemos os pesos abaixo sem a
# necessidade de constantes. Neste caso so' a priori.
#====================================================
library("triangle")
pesos  <- dtriangle(piprop,0,1,b)
prob   <- pesos/sum(pesos)
sum(prob)
z      <- sample(piprop,M,replace=T,prob=prob)
x11()
hist(z,lwd=3,main="",prob=T,xlim=c(0,1),nclass=30,
xlab=expression(pi),ylab=expression(L(pi)))
lines(xpix,ypix/c,lwd=3,col=4)
points(rep(mean(x)/m,2),c(0,max(ypix)/c),type="h",
col=2,lwd=2,lty=1)
lines(xpix,zpix,col=3,lwd=2)
lines(xpix,wpix/d,col=5,lwd=2)
legend(0,10,legend=c("Verossimilhança","EMV","Priori",
"Posteriori"),bty="o",col=c(4,2,3,5),
lwd=rep(2,4),lty=c(1,2,1,1))
#====================================================
# Resumo da distribuicao a posteriori
# Estimativas pontuais e intervalar
#====================================================
mean(z)                       # media a posteriori
median(z)                     # mediana a posteriori
var(z)
sd(z)
# intervalo de credibilidade de 90%
quantile(z,probs=c(0.05,0.95))
# intervalo de credibilidade de 95%
quantile(z,probs=c(0.025,0.975))
source('~/treinamento_machine_learning/Aula_4/exemplo_24.r')
source('~/treinamento_machine_learning/Aula_4/exemplo_25.r')
# rm(list=ls())
#====================================================
# Exemplo de aproximacao assintotica pela Normal
#
#====================================================
# Amostra n=1 e y=3.
#====================================================
y         <- 3
alpha     <- 3             # hiperparametros
beta      <- 3             # hiperparametros
x         <- seq(-2,6,0.01)
lambda1   <- dgamma(x,alpha+y,beta+1)
media1    <- (alpha+y-1)/(beta+1)
var1      <- media1/(beta+1)
lambda2   <- dnorm(x,media1,sqrt(var1))
#====================================================
# Grafico para comparacao
#====================================================
x11()
par(mfrow=c(1,1),lwd=2.0,cex.lab=1.5,cex.axis=1.5,lab=c(10,5,5),
mar=c(5,5,2,2.5),xpd=T,cex.main=2.0)
plot(x,lambda1,type="l",lwd=2,col=1,xlab=expression(lambda),
ylab=expression(paste("f(",lambda,"|y)",sep=" ")))
lines(x,lambda2,lwd=2,col=2,lty=2)
legend("topright",legend=c("Verdadeira","Aproximada"),
col=c(1,2),lty=c(1,2),lwd=c(2,2))
#====================================================
# Lognormal
#====================================================
media2    <- log((alpha+y)/(beta+1))
var2      <- 1/(alpha+y)
lambda3   <- dlnorm(x,media2,sqrt(var2))
#====================================================
# Grafico para comparacao
#====================================================
x11()
par(mfrow=c(1,1),lwd=2.0,cex.lab=1.5,cex.axis=1.5,lab=c(10,5,5),
mar=c(5,5,2,2.5),xpd=T,cex.main=2.0)
plot(x,lambda1,type="l",lwd=2,col=1,xlab=expression(lambda),
ylab=expression(paste("f(",lambda,"|y)",sep=" ")))
lines(x,lambda2,lwd=2,col=2,lty=2)
lines(x,lambda3,lwd=2,col=4,lty=2)
legend("topright",legend=c("Verdadeira","Aproximada Normal",
"Aproximada Lognormal"),col=c(1,2,4),lty=c(1,2,2),lwd=c(2,2,2))
#====================================================
# Fim
#====================================================
